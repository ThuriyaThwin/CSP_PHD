
This study examines improvements to the \astar~algorithm when we have
several available admissible heuristics. Clearly, we can evaluate all
these heuristics, and use their {\em maximum} as an admissible
heuristic, a scheme we call \astarmax.  The problem with naive
maximization is that all the heuristics are computed for all the
generated nodes.  In order to reduce the time spent on heuristic
computations, Lazy $\astar$ (or \lazyastar, for short) evaluates the
heuristics one at a time, lazily.  When a node $n$ is generated,
\lazyastar~only computes one heuristic, $h_1(n)$, and adds $n$ to
\OPEN.  Only when $n$ re-emerges as the top of \OPEN~is another
heuristic, $h_2(n)$, evaluated; if this results in an increased
heuristic estimate, $n$ is re-inserted into \OPEN.  \lazyastar~is as
informative as \astarmax, but can significantly reduce search time, as
we will not need to compute $h_2$ for many nodes.

\lazyastar~reduces the search time, while maintaining the informativeness of \astarmax.
However, if the goal is reducing search time, it is sometimes better
to compute a fast heuristic on several nodes, rather than to compute a
slow but informative heuristic on only one node. We combine the ideas
of lazy heuristic evaluation and of trading off more node expansions
for less heuristic computation time, into a {\em new} variant of
\lazyastar~called {\em rational lazy} \astar~(\rationallazyastar).
\rationallazyastar~is based on rational metareasoning, and uses a
myopic {\em value-of-information} criterion to decide whether to
compute $h_2(n)$ or to bypass the computation of $h_2$ and expand $n$
immediately when $n$ re-emerges from \OPEN. \rationallazyastar~aims to
reduce search time, even at the expense of more node expansions than
\astarmax.

\section{Background and Related Work}

The \astar~algorithm \cite{ASTR68} is a best-first heuristic search
algorithm guided by the cost function $f(n)=g(n)+h(n)$.  If the
heuristic $h(n)$ is admissible (never overestimates the real cost to
the goal) then the set of nodes expanded by \astar~is both necessary
and sufficient to find the optimal path to the goal~\cite{ASTR85}.

Throughout this study we assume for clarity that we have two available
admissible heuristics, $h_1$ and $h_2$.Extension to multiple heuristics is straightforward.
Unless stated otherwise, we assume that $h_1$ is faster to compute than $h_2$
but that $h_2$ is {\em weakly more informed}, i.e., $h_1(n) \leq h_2(n)$ for
the majority of the nodes $n$, although counter cases where $h_1(n) > h_2(n)$
are possible. We say that $h_2$ {\em dominates} $h_1$, if such counter cases do not
exist and $h_2(n) \geq h_1(n)$ for {\em all} nodes $n$.
We use $f_1(n)$ to denote $g(n)+h_1(n)$. Likewise, $f_2(n)$
denotes $g(n)+h_2(n)$, and $f_{max}(n)$ denotes $g(n) + \max(h_1(n),h_2(n))$.
We denote the cost of the optimal solution by $\optcost$. Additionally, we
denote the computation time of $h_1$ and of $h_2$ by $t_1$ and $t_2$,
respectively and denote the overhead of an {\em insert/pop} operation in
\OPEN~by $t_o$. Unless stated otherwise we assume that $t_2$ is much greater
than $t_1 + t_o$. 

\subsection{Selective MAX}

Based on the idea of of trading off more node expansions for less
heuristic computation time, \cite{domshlak-et-al:jair-2012} formulated
{\em selective max} (Sel-MAX), an online learning scheme which chooses
one heuristic to compute at each state. Sel-MAX chooses to compute the
more expensive heuristic $h_2$ for node $n$ when its classifier
predicts that $h_2(n) - h_1(n)$ is greater than some threshold, which
is a function of heuristic computation times and the average branching
factor.

\subsection{Lazy \astar}

The idea behind the \lazyastar~algorithm was briefly mentioned
by~\cite{zhang-bacchus:aaai-2012} in the context of the MAXSAT
heuristic for planning domains. \cite{Helmert.fdps} described
\emph{deferred evaluation} of heuristics in the context of the Fast
Downward Planning System. In deferred evaluation, the successors of
node $n$ are placed in the open list with the heuristic estimate of
$n$ and heuristically evaluated only when expanded.  The technique
bears a similarity to a special case of \lazyastar~where the first
heuristic always returns 0.

The pseudo-code for  \lazyastar~is depicted as Algorithm \ref{LAZYA}.
\lazyastar~mainly aims to reduce computations of $h_2$.
\begin{algorithm}[h]
\caption{Lazy \astar}
\begin{algorithmic}[1]
\Procedure{LAZY-\astar}{}
    \State Apply all heuristics to Start
    \State Insert Start into \OPEN
    \While{\OPEN~ not empty}
        \State $n$ $\gets$ best node from \OPEN
        \If{Goal(n)}
            \Return Trace(n)
        \EndIf
        \If{$h_2$ was not applied to $n$}
            \State Apply $h_2$ to $n$
            State Insert $n$ into \OPEN
			\State {\bf continue} \Comment next node in OPEN
        \EndIf
        \ForAll{child $c$ of $n$}
            \State Apply $h_1$ to $c$
            \State Insert $c$ into \OPEN
        \EndFor
        \State Insert $n$ into \CLOSED
    \EndWhile
    \Return FAILURE
\EndProcedure
\end{algorithmic}
\label{LAZYA}
\end{algorithm}
\lazyastar is very similar to \astar.
In fact, without lines 7 -- 10, \lazyastar~would be identical to
\astar~using the $h_1$ heuristic.
When a node $n$ is generated we only compute $h_1(n)$ and $n$ is added to
\OPEN ~(Lines 11 -- 13), without computing $h_2(n)$ yet.
When $n$ is first removed from \OPEN~(Lines 7 -- 10), we compute $h_2(n)$ and
reinsert it into \OPEN, this time with $f_{max}(n)$.

It is easy to see that \lazyastar~is as informative as \astarmax, in
the sense that both \astarmax~and \lazyastar expand a node $n$ only
if $f_{max}(n)$ is the best $f$-value in \OPEN.  Therefore,
\lazyastar~and \astarmax~generate and expand and the same set of
nodes, up to differences caused by tie-breaking.

In its general form \astar~generates many nodes that it does not expand. These
nodes, called {\em surplus} nodes~\cite{Felner2012}, are in \OPEN~when we
expand the goal node with $f=\optcost$. All nodes in \OPEN~with $f>\optcost$ are
surely surplus but some nodes with $f=\optcost$ may also be surplus. The number
of surplus nodes in OPEN can grow exponentially in the size of the domain, resulting in
significant costs.

\lazyastar~avoids $h_2$ computations for many of these surplus nodes. Consider
a node $n$ that is generated with $f_1(n) > \optcost$. This node is inserted
into \OPEN~but will never reach the top of \OPEN, as the goal node will be found
with $f=\optcost$. In fact, if \OPEN~breaks ties in favor of small $h$-values,
the goal node with $f=\optcost$ will be expanded as soon as it is generated and such
savings of $h_2$ will be obtained for some nodes with $f_1=\optcost$ too. We
refer to such nodes where we saved the computation of $h_2$ as {\em good} nodes. Other nodes,
those with $f_1(n) < \optcost$ (and some with $f_1(n) = \optcost$) are called
{\em regular nodes} as we apply both heuristics for them.

\section{Rational Lazy A*}

Using the principles of rational metareasoning (Section~\ref{sec:ratimeta}),
theoretically every computational operator (heuristic function evaluation, node
expansion, open list operation) should be treated as an action in a sequential
decision-making meta-level problem, and actions should be chosen so as to
achieve the minimal expected search time. However, the appropriate
general metareasoning problem is extremely hard to define precisely, and even harder
to solve optimally.

Therefore, we focus here on just one decision type, to be
made in the context of \lazyastar, when $n$ re-emerges from \OPEN~(Line 8).
We have two options: {\bf (1)}  Evaluate the second heuristic $h_2(n)$ and add
the node back to \OPEN~(Lines 8-10) like \lazyastar, or {\bf 2} bypass the
computation of $h_2(n)$ and expand $n$ right way (Lines 11 -13), thereby
saving timeby not computing $h_2$, at the risk of additional expansions and evaluations of $h_1$.
An method which attempts to
optimally manage this tradeoff, which we call \textit{Rational Lazy A*}, is presented next.
In order to choose rationally we define a criterion based on value of
information (VOI) of evaluating $h_2(n)$ in this context.

The only addition of RLA* to LA* is the option to bypass $h_2$ computations (Lines 8-10).
Suppose that we choose to compute $h_2$ --- this results in one of the
following outcomes:
\begin{enumerate}
\item $n$ is eventually expanded.
\item $n$ is re-inserted into \OPEN, and the goal is found without ever expanding $n$.
\end{enumerate}

Observe that computing $h_2$ can be beneficial only in outcome 2, where
potential time savings are due to pruning a search subtree at the expense of
the time $t_2(n)$. However, whether outcome 2 takes place after a given state
is not known to the algorithm until the goal is found, and the algorithm must
decide whether to evaluate $h_2$ according to what it \textit{believes to be}
the probability of each of the outcomes. We derive a \textit{rational policy}
for when to evaluate $h_2$, under the myopic assumption that the algorithm
continues to behave like \lazyastar~afterwards (i.e., it will never again
consider bypassing the computation of $h_2$).

The time wasted by being sub-optimal in deciding whether to evaluate
$h_2$ is called the {\em regret} of the decision. If $h_2(n)$ is not
helpful and we decide to compute it, the effort for evaluating
$h_2(n)$ turns out to be wasted. On the other hand, if $h_2(n)$ is
helpful but we decide to bypass it, we needlessly expand $n$. Due to
the myopic assumption, \rationallazyastar~would evaluate both $h_1$
and $h_2$ for all successors of $n$.

\begin{table}[h!]
\begin{center}
\begin{tabular}{|l|c|c|}
\hline
               & Compute $h_2$ & Bypass $h_2$\\
\hline
$h_2$ helpful &   0            & $t_e+(b(n)-1)t_d$\\
\hline
$h_2$ not helpful & $t_d$      & 0 \\
\hline
\end{tabular}
\end{center}
\caption{Time losses in Rational Lazy A*}
\label{tbl:rla-rational-lazy-a-time}
\end{table}

Table~\ref{tbl:rla-rational-lazy-a-time}
summarizes the regret of each possible decision, for each possible future
outcome; each column in the table represents a decision, while each row
represents a future outcome.
In the table, $t_d$ is the to time compute $h_2$ and re-insert $n$ into
\OPEN~thus delaying the expansion of $n$, $t_e$ is the time to remove $n$ from \OPEN,
expand $n$, evaluate $h_1$ on each of the $b(n)$ (``local branching factor'')
children $\{n'\}$ of $n$, and insert $\{n'\}$ into the open list.
Computing $h_2$ needless ``wastes'' $t_d$ time.
Bypassing $h_2$ computation when $h_2$ would have been helpful ``wastes''
$t_e+b(n)t_d$ time, but because computing $h_2$ would have cost $t_d$, the
regret is $t_e+(b(n)-1)t_d$.

Let us denote the probability that $h_2$ is helpful by
$p_h$. The expected regret of computing $h_2$ is thus $(1-p_h) t_d$.
On other hand, the expected regret of bypassing $h_2$ is $p_h(
t_e+(b(n)-1)t_d)$. As we wish to minimize the expected regret, we should thus evaluate $h_2$ just when:
\begin{equation}
(1-p_h) t_d < p_h (t_e+(b(n)-1)t_d)
\end{equation}
or equivalently:
\begin{equation}
(1-b(n) p_h) t_d < p_h t_e
\end{equation}

If $p_h b(n) \ge 1$, then the expected regret is minimized by always
evaluating $h_2$, regardless of the values of $t_d$ and $t_e$.  In
these cases, RLA* cannot be expected to do better than \lazyastar.
For example, in the 15-puzzle and its variants, the effective
branching factor is $\approx 2$. Therefore, if $h_2$ is expected to be
helpful for more than half of the nodes $n$ on which
\lazyastar~evaluates $h_2(n)$, then one should simple use \lazyastar.

For $p_h b(n) < 1$,  the decision of whether to evaluate $h_2$
depends on the values of $t_d$ and $t_e$:
\begin{equation}
\mbox{\bf evaluate }h_2\mbox{ \bf if }t_d<\frac {p_h} {1-p_hb(n)} t_e
\label{eqn:rla-criterion-general}
\end{equation}
Let us analyze $t_d$ and $t_e$. Denote by
$t_c$ the time to generate the children of $n$. Then we have:
\begin{align}
t_d&=t_2+t_o\nonumber\\
t_e&=t_o + t_c+b (n) t_1 + b(n) t_o
\label{eqn:rla-t-del-exp-expanded}
\end{align}
By substituting
(\ref{eqn:rla-t-del-exp-expanded}) into (\ref{eqn:rla-criterion-general}), obtain: {\bf evaluate} $h_2$ {\bf if}:
\begin{equation}
{t_2+t_o}<\frac {p_h \left[{t_c} + b (n)t_1+(b(n)+1){t_o}\right]} {1-p_hb(n)}
\label{eqn:rla-criterion-expanded}
\end{equation}
The factor $\frac {p_h} {1-p_hb(n)}$ depends on the potentially unknown
probability $p_h$, making it difficult to reach the optimum decision.
However, if our goal is just to do better than \lazyastar, then it is safe to replace $p_h$ by an upper bound on $p_h$.

We now turn to implementation-specific estimation of the respective runtimes.
\OPEN~in \astar~is frequently implemented as a priority queue, and thus we have, approximately,
$t_o=\tau \log N_o$ for some $\tau$, when the size of \OPEN~is $N_o$.
Evaluating $h_1$ is cheap in many domains, as is the
case with MD in discrete domains, $t_o$ is the most significant part of
$t_{e}$. In such cases,
rule (\ref{eqn:rla-criterion-expanded}) can be approximated as (\ref{eqn:rla-criterion-gamma}):
\begin{align}
  &\mbox{\bf evaluate }h_2\mbox{ \bf if } t_2 < \frac {\tau p_h} {1-p_hb(n)} (b(n)+1)\log N_o
\label{eqn:rla-criterion-gamma}
\end{align}
Rule (\ref{eqn:rla-criterion-gamma})
recommends to evaluate $h_2$ mostly at late stages of the search,
when the open list is large, and in nodes with a higher branching factor.

In other domains, such as planning, both $t_1$ and $t_2$ are
significantly greater than both $t_o$ and $t_c$, and terms
not involving $t_1$ or $t_2$ can be dropped from
(\ref{eqn:rla-criterion-expanded}), resulting in Rule (\ref{eqn:rla-criterion-beta}):
\begin{align}
  &\mbox{\bf evaluate }h_2\mbox{ \bf if } \frac{t_2}{t_1} < \frac {p_hb(n)} {1-p_hb(n)}
\label{eqn:rla-criterion-beta}
\end{align}
The right side of (\ref{eqn:rla-criterion-beta}) grows with $b(n)$, and here it is beneficial to evaluate $h_2$
only for nodes with a sufficiently large branching factor. On rearranging equation \ref{eqn:rla-criterion-beta},
we get the criterion which we actually use for planning domains,
which is to evaluate $h_2$ only when:
\begin{equation}
b(n) > \frac{t_2}{t_1 p_h \left(1 + \frac{t_2}{t_1}\right)}
\label{eqn:rla-planning-rule}
\end{equation}

\section{Empirical Evaluation}
\label{sec:rla-empirical}

\subsection{Weighted 15-puzzle}

In the uniform-cost 15 puzzle, the open list contains only a few
different f-costs, and is frequently implemented using buckets,
violating the assumption of logarithmic time for which RLA* is
beneficial. In order to better evaluate the latter, we therefore use
the weighted 15-puzzle variant, where the cost of moving each tile is
equal to the number on the tile.  For consistency of comparison, we
used a subset of 36 problem instances out of the set of 100 15-puzzle
instances by~\cite{BFID85}, keeping the problems which could be solved
with 2Gb of RAM and 15 minutes timeout using the Weighted Manhattan
heuristic (WMD) for $h_1$. As the second, expensive and informative,
$h_2$ heuristic for \lazyastar~and \rationallazyastar, we a heuristic
based on lookaheads~\cite{DBLP:conf/aaai/SternKFH10}. Given a bound
$d$ we applied a bounded depth-first search from a node $n$ and
backtracked when we reached leaf nodes $l$ for which $g(l)+WMD(l)>
g(n)+WMD(n)+d$. $f$-values from leaves were propagated to $n$.

\begin{table}
\parindent -0.5in
\begin{small}
\begin{tabular}{|c|| r r || r r r || r r r r r | } \hline
&\multicolumn{2}{|c||}{\astar}&\multicolumn{3}{c||}{\lazyastar}&\multicolumn{5}{c|}{\rationallazyastar}\\
\hline
lookahead & generated & time &  Good1 & $N_2$ & time & generated & Good1   & Good2  & $N_2$     & time \\ \hline
         6 & 889,930  & {\bf 0.601}  & 257,598 & 632,332 & 0.462   & 944,750 &  299,479 & 239,320 &  405,951   & 0.446  \\ \hline
         8 & 740,513  & 0.700  & 197,107 & 543,406 & {\bf 0.431}   & 892,216 &  233,370 & 303,655 &  260,823   & 0.402  \\ \hline
         10 & 612,010 & 0.929  & 145,687 & 466,327 & 0.474   & 859,220 &  278,431 & 445,846 &  134,943   & {\bf 0.378}  \\ \hline
         12 & 454,171 & 1.128  & 95,118  & 359,053 & 0.621   & 807,846 &  277,783 & 428,686 &  101,377   & 0.465  \\ \hline
\end{tabular}
\end{small}
\caption{Weighted 15 puzzle: comparison of $A^*_{\max}$, Lazy $A^*$, and Rational Lazy $A^*$}
\label{tbl:rla-rational-lazy-a-star}
\end{table}
Table~\ref{tbl:rla-rational-lazy-a-star} presents the results averaged
on all instances solved. The running times are reported relative
to the time of \astar with WMD (with no lookahead), which generated
2012643 nodes (not reported in the table). The first 3 columns of Table
\ref{tbl:rla-rational-lazy-a-star} shows the results for \astar~with the
lookahead heuristic for different lookahead depths. The best time is
achieved for lookahead 6, (0.601 compared to \astar~with WMD). The fact
that the time is not continuing to decrease with deeper lookaheads is
clearly due to the fact that although the resulting heuristic improves
as a function of lookahead depth (expanding and generating fewer nodes),
the increasing overheads of computing the heuristic eventually outweights
the computation time it saved by expanding fewer nodes.


The next 3 columns show the results for \lazyastar~ with WMD as $h_1$,
lookahead as $h_2$, for different lookahead depths
(\lazyastar~generates the same number of nodes as \astar).  The {\em
  Good1} column presents the number of nodes where \lazyastar saved
the computation of $h_2$ while the $N_2$ column presents the number of
nodes where $h_2$ was computed. $\approx 28\%$ of nodes were {\em
  Good1} and since $t_2$ was the most dominant time cost, most of this
saving is reflected in the timing results.  The best results are
achieved for lookahead 8, with a runtime of 0.431 compared to \astar~
with WMD.

The final columns show the results of RLA* with different lookaheads for
empirically best values of $\tau$. The {\em Good2} column counts the
number of times that RLA* decided to bypass the $h_2$ computation and
expand the node right away.Observe that RLA* outperforms \lazyastar,
which in turn outperforms standard A*, for all lookahead depths. The
lowest time with RLA* (0.378 of \astar with WMD) and empirically best
$\tau$  was obtained for lookahead 10. That is achieved because the
more expensive $h_2$ heuristic is computed less often, reducing its
effective computational overhead, with little or no adverse effect in
the number of expanded nodes. Although LA* expanded fewer nodes, RLA*
performed much fewer $h_2$ computations as can be seen in the table,
resulting in decreased overall runtimes for all lookahead depths.

The case of both $t_1$ and $t_2$ being significantly larger than $t_o$
and $t_c$ can also be modeled using the 15-puzzle domain by considering only the
time spent evaluating the heuristics. Table~\ref{tbl:rla-amax-la-rla-times}
presents the results of solving the Weighted 15-puzzle obtained on
the the set of 100 15-puzzle instances by~\cite{BFID85}, using the
combination of weighted Manhattan distance and weigthed linear
conflict \cite{hanssonmy.linconflict} heuristics. Rows $N_1$ and $N_2$ present the
average numbers of evaluations of $h_1$ and $h_2$, rows $T_1$ and
$T_2$ the average total times (per instance) spent evaluating each
of the heuristics.
\begin{table}[h!]
\begin{center}
\begin{tabular}{|l | c | c | c | } \hline
  &\astarmax&\lazyastar&\rationallazyastar\\ \hline 
$N_1$ & 1,482,271 & 1,482,271 & 1,521,163 \\ \hline
$T_1, sec$ & 0.979     & 0.979     & 1.026 \\ \hline
$N_2$ & 1,482,271 & 1,117,826 & 868,182 \\ \hline
$T_2, sec$ & 4.122     & 2.425     & 1.938 \\ \hline
$T_1+T_2, sec$ & 5.101 & 3.404    & 2.964 \\ \hline
\end{tabular}
\end{center}
\caption{Weighted 15 puzzle: comparison of heuristic computation times
in $A^*_{\max}$, Lazy $A^*$, and Rational Lazy $A^*$} 
\label{tbl:rla-amax-la-rla-times}
\end{table}
\astarmax~evaluates both $h_1$ and $h_2$ on both nodes and is obviously
the slowest. \lazyastar~evaluates $h_2$ selectively, spending 40\%
less time evaluating $h_2$ and 33\% less time
overall. \rationallazyastar, using Rule~(\ref{eqn:rla-planning-rule}),
spends 20\% less time than \lazyastar~evaluating $h_2$ \emph{at the
  expense} of spending 4\% more time evaluating $h_1$, and takes
12\% less time than \lazyastar~and 40\% less time than \astarmax~overall.

\subsection{Planning Domains}

\cite{TolpinEtAl.rla} presents results for comparing \rationallazyastar and
other algorithms on 42 planning domains. In these domains, time spent evaluating
heuristics constitutes approximately 90\% of the total search time,
hence applying rule~(\ref{eqn:rla-planning-rule}) is justified. 
\rationallazyastar~was compared to \lazyastar~and to \astar~using
each of the heuristics individually, as well as to the max-based
combination of the heuristics, and to the combination using selective-max
(Sel-MAX)~\cite{domshlak-et-al:jair-2012}. In the evaluation, 
\rationallazyastar~solved most problem instances in the shortest
total search time.
\begin{table}[h!]
\parindent -0.5in
\tiny{
\begin{tabular}{|l|r|r|r|r|r|r||r|r|r|r|r|r||r|r|r|r|r|r||r|r|}
\hline &
\multicolumn{6}{|c||}{Problems Solved } &
\multicolumn{6}{|c||}{Planning Time (seconds)} &
%\multicolumn{6}{|c||}{Expansions (623)} &
\multicolumn{2}{|c|}{GOOD } \\
\hline Domain &
$h_{LA}$ & lmcut & max & selmax & \lazyastar& \rationallazyastar &
$h_{LA}$ & lmcut & max & selmax & \lazyastar& \rationallazyastar &
%$h_1$ & $h_2$ & M & S & L& R &
\lazyastar& \rationallazyastar \\

\hline airport & 25 & 24 & 26 & 25 & \textbf{29} & \textbf{29} & \textbf{0.29} & 0.57 & 0.5 & 0.33 & 0.38 & 0.38 & 0.48 & 0.67 \\
barman-opt11 & \textbf{4} & 0 & 0 & 0 & 0 & 3 & N/A & N/A & N/A & N/A & N/A & N/A & N/A & N/A \\
blocks & 26 & 27 & 27 & 27 & \textbf{28} & \textbf{28} & 1.0 & \textbf{0.65} & 0.73 & 0.81 & 0.67 & 0.67 & 0.19 & 0.21 \\
depot & \textbf{7} & 6 & 5 & 5 & 6 & 6 & \textbf{2.27} & 2.69 & 3.17 & 3.14 & 2.73 & 2.75 & 0.06 & 0.06 \\
driverlog & 10 & \textbf{12} & \textbf{12} & \textbf{12} & \textbf{12} & \textbf{12} & 2.65 & \textbf{0.29} & 0.33 & 0.36 & 0.3 & 0.31 & 0.09 & 0.09 \\
elevators-opt08 & 12 & \textbf{18} & 17 & 17 & 17 & 17 & 14.14 & 4.21 & 4.84 & 4.85 & \textbf{3.56} & 3.64 & 0.27 & 0.27 \\
elevators-opt11 & 10 & \textbf{14} & \textbf{14} & \textbf{14} & \textbf{14} & \textbf{14} & 26.97 & 8.03 & 9.28 & 9.28 & \textbf{6.64} & 6.78 & 0.28 & 0.28 \\
floortile-opt11 & 2 & \textbf{6} & \textbf{6} & \textbf{6} & \textbf{6} & \textbf{6} & 8.52 & \textbf{0.44} & 0.6 & 0.58 & 0.5 & 0.52 & 0.02 & 0.02 \\
freecell & \textbf{54} & 10 & 36 & 51 & 41 & 41 & \textbf{0.16} & 7.34 & 0.22 & 0.24 & 0.18 & 0.18 & 0.86 & 0.86 \\
grid & \textbf{2} & \textbf{2} & 1 & \textbf{2} & \textbf{2} & \textbf{2} & \textbf{0.1} & 0.16 & 0.18 & 0.34 & 0.15 & 0.15 & 0.17 & 0.17 \\
gripper & \textbf{7} & 6 & 6 & 6 & 6 & 6 & \textbf{0.84} & 1.53 & 2.24 & 2.2 & 1.78 & 1.25 & 0.01 & 0.4 \\
logistics00 & \textbf{20} & 17 & 16 & \textbf{20} & 19 & 19 & \textbf{0.23} & 0.57 & 0.68 & 0.27 & 0.47 & 0.47 & 0.51 & 0.51 \\
logistics98 & 3 & \textbf{6} & \textbf{6} & \textbf{6} & \textbf{6} & \textbf{6} & 0.72 & \textbf{0.1} & 0.1 & 0.11 & \textbf{0.1} & \textbf{0.1} & 0.07 & 0.07 \\
miconic & \textbf{141} & 140 & 140 & \textbf{141} & \textbf{141} & \textbf{141} & \textbf{0.13} & 0.55 & 0.58 & 0.57 & 0.16 & 0.16 & 0.87 & 0.88 \\
mprime & 16 & 20 & 20 & 20 & \textbf{21} & 20 & 1.27 & 0.5 & 0.51 & 0.5 & \textbf{0.44} & 0.45 & 0.25 & 0.25 \\
mystery & 13 & \textbf{15} & \textbf{15} & \textbf{15} & \textbf{15} & \textbf{15} & 0.71 & \textbf{0.35} & 0.38 & 0.43 & 0.36 & 0.37 & 0.3 & 0.3 \\
nomystery-opt11 & \textbf{18} & 14 & 16 & \textbf{18} & \textbf{18} & \textbf{18} & \textbf{0.18} & 1.29 & 0.58 & 0.25 & 0.33 & 0.33 & 0.72 & 0.72 \\
openstacks-opt08 & 15 & \textbf{16} & 14 & 15 & \textbf{16} & \textbf{16} & 2.88 & \textbf{1.68} & 3.89 & 3.03 & 2.62 & 2.64 & 0.44 & 0.45 \\
openstacks-opt11 & 10 & \textbf{11} & 9 & 10 & \textbf{11} & \textbf{11} & 13.59 & \textbf{6.96} & 19.8 & 14.44 & 12.03 & 12.06 & 0.43 & 0.43 \\
parcprinter-08 & 14 & \textbf{18} & \textbf{18} & \textbf{18} & \textbf{18} & \textbf{18} & 0.92 & \textbf{0.36} & 0.37 & 0.38 & 0.37 & 0.37 & 0.17 & 0.26 \\
parcprinter-opt11 & 10 & \textbf{13} & \textbf{13} & \textbf{13} & \textbf{13} & \textbf{13} & 2.24 & \textbf{0.56} & 0.6 & 0.61 & 0.58 & 0.59 & 0.14 & 0.17 \\
parking-opt11 & 1 & 1 & 1 & \textbf{3} & 2 & 2 & 9.74 & 22.13 & 17.85 & 7.11 & \textbf{6.33} & 6.43 & 0.64 & 0.64 \\
pathways & 4 & \textbf{5} & \textbf{5} & \textbf{5} & \textbf{5} & \textbf{5} & 0.5 & \textbf{0.1} & \textbf{0.1} & \textbf{0.1} & \textbf{0.1} & \textbf{0.1} & 0.1 & 0.12 \\
pegsol-08 & \textbf{27} & \textbf{27} & \textbf{27} & \textbf{27} & \textbf{27} & \textbf{27} & 1.01 & \textbf{0.84} & 1.2 & 1.1 & 1.06 & 0.95 & 0.04 & 0.42 \\
pegsol-opt11 & \textbf{17} & \textbf{17} & \textbf{17} & \textbf{17} & \textbf{17} & \textbf{17} & 4.91 & \textbf{3.63} & 5.85 & 5.15 & 4.87 & 4.22 & 0.04 & 0.38 \\
pipesworld-notankage & \textbf{16} & 15 & 15 & \textbf{16} & 15 & 15 & \textbf{0.5} & 1.48 & 1.12 & 0.85 & 0.9 & 0.91 & 0.42 & 0.42 \\
pipesworld-tankage & \textbf{11} & 8 & 9 & 9 & 9 & 9 & \textbf{0.36} & 2.24 & 1.02 & 0.47 & 0.69 & 0.71 & 0.62 & 0.62 \\
psr-small & \textbf{49} & 48 & 48 & \textbf{49} & 48 & 48 & \textbf{0.15} & 0.2 & 0.21 & 0.19 & 0.19 & 0.18 & 0.17 & 0.49 \\
rovers & 6 & \textbf{7} & \textbf{7} & \textbf{7} & \textbf{7} & \textbf{7} & 0.74 & \textbf{0.41} & 0.45 & 0.45 & 0.41 & 0.42 & 0.47 & 0.47 \\
scanalyzer-08 & 6 & \textbf{13} & \textbf{13} & \textbf{13} & \textbf{13} & \textbf{13} & 0.37 & \textbf{0.25} & 0.27 & 0.27 & 0.26 & 0.26 & 0.06 & 0.06 \\
scanalyzer-opt11 & 3 & \textbf{10} & \textbf{10} & \textbf{10} & \textbf{10} & \textbf{10} & \textbf{0.59} & 0.64 & 0.75 & 0.73 & 0.67 & 0.68 & 0.05 & 0.05 \\
sokoban-opt08 & 23 & 25 & 25 & 24 & 26 & \textbf{27} & 3.94 & 1.76 & 2.19 & 2.96 & 1.9 & \textbf{1.32} & 0.04 & 0.4 \\
sokoban-opt11 & \textbf{19} & \textbf{19} & \textbf{19} & 18 & \textbf{19} & \textbf{19} & 7.26 & 2.83 & 3.66 & 5.19 & 3.1 & \textbf{2.02} & 0.03 & 0.46 \\
storage & 14 & \textbf{15} & 14 & 14 & \textbf{15} & \textbf{15} & \textbf{0.36} & 0.44 & 0.49 & 0.45 & 0.44 & 0.42 & 0.21 & 0.28 \\
tidybot-opt11 & \textbf{14} & 12 & 12 & 12 & 12 & 12 & \textbf{3.03} & 16.32 & 17.55 & 9.35 & 15.67 & 15.02 & 0.11 & 0.18 \\
tpp & \textbf{6} & \textbf{6} & \textbf{6} & \textbf{6} & \textbf{6} & \textbf{6} & 0.39 & \textbf{0.22} & 0.23 & 0.23 & 0.22 & 0.22 & 0.32 & 0.4 \\
transport-opt08 & \textbf{11} & \textbf{11} & \textbf{11} & \textbf{11} & \textbf{11} & \textbf{11} & 1.45 & \textbf{1.24} & 1.41 & 1.54 & 1.25 & 1.26 & 0.04 & 0.04 \\
transport-opt11 & \textbf{6} & \textbf{6} & \textbf{6} & \textbf{6} & \textbf{6} & \textbf{6} & 12.46 & \textbf{8.5} & 10.38 & 11.13 & 8.56 & 8.61 & 0.0 & 0.0 \\
trucks & 7 & \textbf{9} & \textbf{9} & \textbf{9} & \textbf{9} & \textbf{9} & 4.49 & \textbf{1.34} & 1.52 & 1.44 & 1.41 & 1.42 & 0.07 & 0.07 \\
visitall-opt11 & 12 & 10 & \textbf{13} & 12 & \textbf{13} & \textbf{13} & 0.2 & 0.34 & 0.19 & \textbf{0.18} & 0.18 & 0.18 & 0.38 & 0.38 \\
woodworking-opt08 & 12 & \textbf{16} & \textbf{16} & \textbf{16} & \textbf{16} & \textbf{16} & 1.08 & 0.71 & 0.75 & 0.75 & \textbf{0.66} & 0.67 & 0.56 & 0.56 \\
woodworking-opt11 & 7 & \textbf{11} & \textbf{11} & \textbf{11} & \textbf{11} & \textbf{11} & 5.7 & 2.86 & 3.15 & 3.01 & \textbf{2.55} & 2.58 & 0.52 & 0.52 \\
zenotravel & 8 & \textbf{11} & \textbf{11} & \textbf{11} & \textbf{11} & \textbf{11} & 0.38 & \textbf{0.14} & 0.14 & 0.14 & 0.14 & 0.14 & 0.17 & 0.19 \\
\hline
OVERALL & 698 & 697 & 722 & 747 & 747 & \textbf{750} & 1.18 & 0.98 & 0.98 & 0.89 & 0.79 & \textbf{0.77} & 0.27 & 0.34 \\
\hline
\end{tabular}
}
\begin{small}
\caption{\label{tbl:rla-planning} Planning Domains --- Number of Problems
Solved, Total Planning Time, and Fraction of Good Nodes}
\end{small}
\end{table}

Table~\ref{tbl:rla-planning} depicts the experimental results
(provided by Erez Karpas). \lazyastar~and \rationallazyastar~were
implemented on top of the Fast Downward
planning system \cite{helmert:jair-2006}, and two state
of the art heuristics were used: the admissible landmarks heuristic $h_{LA}$ (used as $h_1$)
\cite{karpas-domshlak:ijcai-2009}, and the landmark cut heuristic $h_{LMCUT}$
\cite{helmert-domshlak:icaps-2009} (used as $h_2$).
On average, $h_{LMCUT}$ computation is 8.36 times more expensive than $h_{LA}$
computation.

The leftmost part of the table shows the number of solved problems in each
domain. As the table demonstrates, \rationallazyastar~solves the most problems,
and \lazyastar~solves the same number of problems as Sel-MAX. Thus, both
\lazyastar~and \rationallazyastar~are state-of-the-art in cost-optimal planning.
Looking more closely at the results, note that Sel-MAX
solves 10 more problems than \lazyastar~and \rationallazyastar~in the freecell
domain. Freecell is one of only three domains in which $h_{LA}$ is more
informed than $h_{LMCUT}$ ~(the other two are nomystery-opt11 and
visitall-opt11), violating the basic assumptions behind 
\lazyastar~ that $h_2$ is more informed than $h_1$. If
we ignore these domains, both \lazyastar~and \rationallazyastar~solve more
problems than Sel-MAX.

The middle part of the Table~\ref{tbl:rla-planning} shows the geometric mean of
planning time in each domain, over the commonly solved problems (i.e., those
that were solved by all 6 methods). \rationallazyastar~is the fastest overall,
with \lazyastar~second. It is important to note that both \lazyastar~and
\rationallazyastar~are very robust, and even in cases where they are not the
best they are never too far from the best. For example, consider the {\em
miconic} domain. Here,  $h_{LA}$ is very informative and thus the variant that
only computed $h_{LA}$ is the best choice (but a bad choice overall). Observe
that both  \lazyastar~and \rationallazyastar~saved 86\% of $h_{LMCUT}$
computations, and were very close to the best algorithm in this extreme case.
In contrast, the other algorithms that consider both heuristics (max and
Sel-MAX) performed very poorly here (more than three times slower).

The rightmost part of Table~\ref{tbl:rla-planning} shows the average
fraction of nodes for which \lazyastar~ and \rationallazyastar~did not evaluate
the more expensive heuristic, $h_{LMCUT}$, over the problems solved by both
these methods.
This is shown in the {\em good} columns. Our first observation is that this
fraction varies between different domains, indicating why \lazyastar~works well
in some domains, but not in others. Additionally, we can see that in domains
where there is a difference in this number between \lazyastar~and
\rationallazyastar, \rationallazyastar~usually performs better in terms of
time. This indicates that when \rationallazyastar~decides to skip the
computation of the expensive heuristic, it is usually the right
decision. 

\begin{table}[h!]
\begin{center}
\begin{small}
\begin{tabular}{|l|r|r|}
\hline
&  Expanded & Generated\\
\hline
$h_{LA}$     & 183,320,267 & 1,184,443,684\\
lmcut    & 23,797,219 & 114,315,382\\
\astarmax          & 22,774,804 & 108,132,460\\
selmax          & 54,557,689 & 193,980,693\\
\hline
$\lazyastar$  & 22,790,804 & 108,201,244\\
$\rationallazyastar$   & 25,742,262 & 110,935,698\\
\hline
\end{tabular}
\end{small}
\end{center}
\caption{\label{tbl:rla-planning-states} Total Number of Expanded and Generated States}
\end{table}

Table~\ref{tbl:rla-planning-states} shows the total number of expanded and generated
states over all commonly solved problems. \lazyastar~is indeed as informative
as \astarmax~(the small difference is caused by tie-breaking), while
\rationallazyastar~is a little less informed and expands slightly more nodes.
However, \rationallazyastar~is much more informative than its ``intelligent''
competitor - Sel-MAX, as these are the only two algorithms in our set
which selectively omit some heuristic computations.
\rationallazyastar~generated almost half of the nodes compared to
Sel-MAX, suggesting that its decisions are better. 


\section{Conclusion and Further Research}

We discussed two schemes for decreasing heuristic evaluation
times. \lazyastar~is very simple to implement and is as informative as
\astarmax. \lazyastar~can significantly speed up the search,
especially if $t_2$ dominates the other time costs, as seen in
weighted 15 puzzle and planning domains.  Rational \lazyastar~allows
additional cuts in $h_2$ evaluations, at the expense of being less
informed than \astarmax. However, due to a rational tradeoff, this
allows for an additional speedup, and Rational \lazyastar~achieves the
best overall performance in our domains.

In particular, \rationallazyastar~is simpler to implement than its direct
competitor, selective max, but its decision can be more informed.  When
\rationallazyastar~has to decide whether to compute $h_2$ for some node
$n$, it already {\em knows} that $f_1(n) \leq \optcost$.  By contrast,
although selective max uses a much more complicated decision rule, it
chooses which heuristic to compute when $n$ is first generated, and does
not know whether $h_1$ will be informative enough to prune $n$. Rational
\lazyastar~outperforms selective max in our planning experiments.

There are numerous other ways to use rational metareasoning to
improve~\astar, starting from generalizing \rationallazyastar~to
handle more than two heuristics, to using the meta-level to control
decisions in other variants of \astar. All these potential extensions
provide fruitful ground for further research.
